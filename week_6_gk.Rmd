---
title: "Week 6 Code-Along"
author: "Grace Kumaishi"
date: "11/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(palmerpenguins)
library(ggpubr)
library(broom)
```

Create two sample vectors gp_1 and gp_2
```{r}
set.seed(1414)
gp_1 <- sample.int(20, size = 15, replace = TRUE)

set.seed(1424)
gp_2 <- sample.int(30, size = 15, replace = TRUE)

gp_1
gp_2
```

Histograms of gp_1 and gp_2:

-> Is there evidence for a significant difference in ranks (medians) between the populations from which gp_1 and gp_2 were drawn?

```{r}
hist(gp_1)
hist(gp_2)
```

If I want to compare ranks between gp_1 and gp_2, what are some reasons I might choose a rank-based test?

1) Not clearly normally distributed from exploratory histograms

2) Somewhat small sample size (n = 15 for each)

3) I've decided that ranks (medians) are a more valuable metric to compare for these data

Here, we'll perform a Mann-Whitney U to answer "is there a significant difference in ranks (medians) between gp_1 and gp_2?

```{r}
my_mwu <- wilcox.test(gp_1, gp_2)

my_mwu
```

# Penguins!

### A. Look at the data

Exploratory scatterplot of penguin flipper length versus body mass:

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point()
```

We should ask questions about our exploratory visualization:

1) Does it look like a linear relationship makes sense?

2) Do we have any concerns about modeling as a linear relationship?

3) Any notable outliers?

4) Initial thoughts about homoscedasticity?

Here, it looks like overall a linear relationship between flipper length and body mass makes sense here. 

Once we've decided that a linear relationship makes sense, we'll model it using lm().

Note that we haven't checked all assumptions yet. That's because a lot of our assumptions for linear regression are based on model *residuals* (e.g. normality and homoscedasticity of residuals), which we can't calculate until after we find the predicted values from the model (residual = y(actual) - y(predicted)).

### B. Model it

Make the model first:
```{r}
penguin_lm <- lm(body_mass_g ~ flipper_length_mm, data = penguins)

summary(penguin_lm)
```

- Both the intercept and flipper_length_mm coefficients are significantly different from zero (not super interesting)

- The multiple R^2 value is 0.759 - meaning that 75.9% of variance in body mass is explained by flipper length. 

### C. Access model outputs

We can access the coefficients for the model using:

- The slope is 49.69 (g/mm)
- The y-intercept is -5780.83 (g)
- The full equation is mass = 49.69*(flipper length) - 5780.83

We can use the broom::tidy() function to get the model outputs in a nice data frame format:

```{r}
penguin_lm_tidy <- broom::tidy(penguin_lm)

penguin_lm_tidy
```

Some examples:

```{r}
# Get the intercept:
penguin_int <- penguin_lm_tidy$estimate[1]
penguin_int
```

```{r}
# Then to get the flipper length coefficient:
penguin_coef <- penguin_lm_tidy$estimate[2]
penguin_coef
```

What about getting some other model info (degrees of freedom, F-statistic, p-value, etc.)?

Many of these statistical outcomes can be accessed more easily using broom::glance().

```{r}
# Metrics at a glance:
penguin_lm_out <- broom::glance(penguin_lm)
penguin_lm_out
```

We can use the results of both to write a statement about the model that will **automatically update** if anything about the model changes! Make sure to look at the .Rmd (not just this knitted html) to learn how to reference the outputs automatically in text. For example: 

"Simple linear regression was used to explore the relationship between penguin flipper length (mm) and body mass (g) across all three penguin species, and including both male and female penguins. A significant regression model was found ($\beta$ = `r round(penguin_coef,3)`, F(`r penguin_lm_out$df`,`r penguin_lm_out$df.residual`) = `r round(penguin_lm_out$statistic,1)`, p < 0.001) with an R^2^ of `r round(penguin_lm_out$r.squared,3)`."

**Note:** This might seem *really* tedious to write out, but the advantages are worth it. All values will be automatically updated when the model is updated! Reproducible and way less opportunity for human error. Plus, once you have this template statement made, you can reuse it for future regression models and just replace `penguin_lm_out` and `penguin_coef` with the appropriate objects for your new model! 

Note that I use "p < 0.001" here if the p-value is very small - this is somewhat standard. 

### D. Explore model assumptions

Recall that we have assumptions for linear regression we need to explore, some related to the residuals.

- Linearly related variables (CHECK - already looked and thought hard)
- Normally distributed residuals
- Homoscedasticity (constant residuals variance)
- iid residuals (no serial correlation) - more often a concern in time series data

Use the plot() function on the model, which will automatically create four useful visualizations to consider assumptions!

```{r}
plot(penguin_lm)
```

Notice that four plots show up. What do they show?

- **The first one:** fitted values vs. residuals
- **The second one:** QQ-plot for residuals
- **The third one:** another way of looking at fitted vs. residuals (these are just standardized residuals, but you can interpret it in the same way)
- **The fourth one:** Cook's distance, a measure of "influence" or "leverage" that individual points have on the model - often considered a way to explore outliers. 

Graphs 1 & 3 are useful for thinking about homoscedasticity; graph 2 (QQ plot) helps us consider normality of residuals; graph 4 reveals the Cook's distance (a measure of how much leverage any single observation has on the model).

### E. Visualize the model

Now that we've explored the assumptions and have decided that linear regression is a valid tool to describe the relationship between flipper length and body mass, let's look at the model. 

- Use geom_smooth(method = "lm") to add a linear model to an existing scatterplot
- Use stat_cor() and/or stat_regline_equation() to add equation information directly to the plot panel, at an x- and y-position that you specify (and yes, you can mess with the digits and appearance here)

```{r}
ggplot(data = penguins, aes(x = flipper_length_mm, y = body_mass_g)) +
  geom_point(size = 2) +
  geom_smooth(method = "lm",
              color = "red",
              size = 0.5,
              fill = "gray10",
              alpha = 0.5) +
  theme_light() +
  ggpubr::stat_regline_equation(label.x = 180, label.y = 5700)
```

### F. Find Pearson's r for correlation:

Pearson's r ranges in value from -1 (perfectly negatively correlated - as one variable increases the other decreases) to 1 (perfectly positively correlated - as one variable increases the other increases). A correlation of 0 means that there is no degree of relationshp between the two variables. 

Typical guidelines look something like this (there's wiggle room in there):

- r = 0: no correlation
- r < |0.3|: weak correlation
- r between |0.3| and |0.7|: moderate correlation
- r > |0.7|: strong correlation

We'll use the cor.test() function, adding the two vectors (flipper_length_mm and body_mass_g) as the arguments. The function reports the Pearson's r value, and performs a hypothesis test with null hypothesis that the correlation = 0. 

```{r}
penguins_cor <- cor.test(penguins$flipper_length_mm, penguins$body_mass_g)

penguins_cor
```

Here, we see that there is a strong positive correlation between penguins flipper length and body mass (r = 0.87, t(340) = 32.72, p<0.001).














